from fastapi import FastAPI, HTTPException, status, UploadFile, File, Form, Depends, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse, Response
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any, Literal, Union, Tuple
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv
import logging
import logging.handlers
from enum import Enum
import openai
import traceback
import json

from app.config import (
    get_settings,
    get_openai_client,
    get_embeddings,
    get_pinecone,
    get_supabase_client,
    get_sendgrid_client,
    get_google_calendar_client
)

from app.agents.langchain.agents.candidate_intake_agent import CandidateIntakeAgent
from app.agents.langchain.agents.job_matching_agent import JobMatchingAgent
from app.agents.langchain.agents.farming_matching_agent import FarmingMatchingAgent
from app.agents.langchain.agents.interview_agent import InterviewAgent
from app.agents.langchain.agents.follow_up_agent import FollowUpAgent

from app.agents.langchain.tools.document_processing import PDFProcessor, ResumeParser
from app.agents.langchain.tools.vector_store import VectorStoreTool
from app.agents.langchain.tools.matching import MatchingTool
from app.agents.langchain.tools.communication import EmailTool, CalendarTool

from app.agents.langchain.chains.candidate_processing import CandidateProcessingChain
from app.agents.langchain.chains.job_matching import JobMatchingChain
from app.agents.langchain.chains.interview_scheduling import InterviewSchedulingChain
from app.agents.langchain.chains.follow_up import FollowUpChain

from app.services.candidate_service import CandidateService
from app.services.job_service import JobService
from app.agents.brain_agent import BrainAgent
from app.schemas.candidate import CandidateCreate, CandidateResponse, CandidateUpdate
from app.schemas.job import JobCreate, JobResponse, JobUpdate
from app.schemas.matching import MatchingResponse
from app.api.webhook import handler as webhook_handler

# Configure logging for serverless environment
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    force=True,  # Force reconfiguration of the root logger
    handlers=[
        logging.StreamHandler()  # Console handler for terminal output
    ]
)

# Create logger for this module
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Ensure third-party loggers don't overwhelm our logs
logging.getLogger('httpx').setLevel(logging.WARNING)
logging.getLogger('openai').setLevel(logging.WARNING)
logging.getLogger('pinecone').setLevel(logging.WARNING)
logging.getLogger('langchain').setLevel(logging.WARNING)

# Test logging configuration
logger.info("\n=== Starting Anita AI Recruitment API ===")
logger.info(f"Environment: {os.getenv('VERCEL_ENV', 'development')}")
logger.info("=====================================\n")

# Load environment variables
load_dotenv()

# Initialize FastAPI app
app = FastAPI(
    title="Anita AI Recruitment API",
    description="API for AI-driven recruitment with enhanced candidate-job matching",
    version="2.0.0"
)

# Mount static files
app.mount("/public", StaticFiles(directory="public"), name="public")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, replace with specific origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize services
settings = get_settings()
llm = get_openai_client()
embeddings = get_embeddings()
pinecone = get_pinecone()
supabase = get_supabase_client()
sendgrid = get_sendgrid_client()
calendar = get_google_calendar_client()

# Initialize vector stores
jobs_index = pinecone.Index(settings.pinecone_jobs_index)
candidates_index = pinecone.Index(settings.pinecone_candidates_index)

# Initialize tools
pdf_processor = PDFProcessor()
resume_parser = ResumeParser()
vector_store = VectorStoreTool()
matching_tool = MatchingTool()
email_tool = EmailTool()
calendar_tool = CalendarTool()

# Initialize chains
candidate_processing_chain = CandidateProcessingChain()
job_matching_chain = JobMatchingChain()
interview_scheduling_chain = InterviewSchedulingChain()
follow_up_chain = FollowUpChain()

# Initialize agents with emoji identifiers
candidate_intake_agent = CandidateIntakeAgent()
candidate_intake_agent.emoji = "üë§"  # Person emoji for candidate intake
job_matching_agent = JobMatchingAgent()
job_matching_agent.emoji = "üîç"  # Magnifying glass for job matching
farming_matching_agent = FarmingMatchingAgent()
farming_matching_agent.emoji = "üåæ"  # Wheat for farming
interview_agent = InterviewAgent()
interview_agent.emoji = "üéØ"  # Target for interview
follow_up_agent = FollowUpAgent()
follow_up_agent.emoji = "üìß"  # Envelope for follow-up

# Log agent initialization
logger.info("\n=== Initializing LangChain Agents ===")
logger.info(f"{candidate_intake_agent.emoji} Candidate Intake Agent")
logger.info(f"{job_matching_agent.emoji} Job Matching Agent")
logger.info(f"{farming_matching_agent.emoji} Farming Matching Agent")
logger.info(f"{interview_agent.emoji} Interview Agent")
logger.info(f"{follow_up_agent.emoji} Follow-up Agent")
logger.info("=====================================\n")

# Dependencies
def get_brain_agent():
    return BrainAgent()

@app.get("/health")
def health_check():
    return {"status": "healthy", "timestamp": datetime.utcnow().isoformat()}

# Retell webhook endpoint
@app.post("/webhook/retell")
async def retell_webhook(request: Request):
    """Handle Retell webhook events."""
    logger.info("üîç FastAPI received Retell webhook request")
    logger.info(f"üîç Request path: {request.url.path}")
    logger.info(f"üîç Request method: {request.method}")
    logger.info(f"üîç Request headers: {dict(request.headers)}")
    
    try:
        # Get raw body for signature verification
        body = await request.json()
        logger.info(f"üîç Request body: {json.dumps(body, indent=2)}")
        
        response = await webhook_handler(request)
        logger.info(f"‚úÖ Webhook handler returned response: {response}")
        
        # If status code is 204, return an empty response
        if response.get("statusCode") == 204:
            return Response(status_code=204)
            
        # Otherwise convert the webhook handler response to a FastAPI response
        status_code = response.get("statusCode", 500)
        headers = response.get("headers", {})
        body = json.loads(response.get("body", "{}"))
        
        return JSONResponse(
            status_code=status_code,
            content=body,
            headers=headers
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error in FastAPI webhook route: {str(e)}")
        logger.error(f"‚ùå Full traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

# Configure OpenAI
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY environment variable is not set")

# Get Vercel protection bypass secret
VERCEL_PROTECTION_BYPASS = os.getenv('VERCEL_PROTECTION_BYPASS')
if not VERCEL_PROTECTION_BYPASS:
    raise ValueError("VERCEL_PROTECTION_BYPASS environment variable is not set")

# Initialize OpenAI client
openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)

class RetellCallStatus(str, Enum):
    CREATED = "created"
    RINGING = "ringing"
    IN_PROGRESS = "in_progress"
    ENDED = "ended"
    ERROR = "error"
    ERROR_UNKNOWN = "error_unknown"

class JobMatchRequest(BaseModel):
    job_id: str
    top_k: Optional[int] = Field(default=5, gt=0, le=100)

class ScopeOfImpact(str, Enum):
    TEAM = "Team"
    DEPARTMENT = "Department"
    COMPANY = "Company"
    INDUSTRY = "Industry"

class CallStatusRequest(BaseModel):
    """Request model for checking call status"""
    candidate_id: str
    call_id: str

# Remove duplicate Pinecone initialization since we're using the config service
logger.info("Using configured Pinecone instance...")

# Remove duplicate index initialization since we already have it from the config
logger.info(f"Using jobs index: {settings.pinecone_jobs_index}")
logger.info(f"Using candidates index: {settings.pinecone_candidates_index}")

# Remove legacy agent initialization since we're using the new LangChain agents
logger.info("Using LangChain agents for processing...")

@app.on_event("startup")
async def startup_event():
    """Initialize services on startup"""
    try:
        logger.info("Application startup complete")
    except Exception as e:
        logger.error(f"Startup error: {str(e)}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """Clean up on shutdown"""
    try:
        logger.info("Application shutdown complete")
    except Exception as e:
        logger.error(f"Shutdown error: {str(e)}")

# ... rest of the file with remaining endpoints and functionality ...